{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5323f328-a3d0-4a29-b1c0-ef69699b9bd6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1257e1e1-13fc-40ab-9429-7c0480099a83",
   "metadata": {},
   "source": [
    "# PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a1175c-ded6-42e9-ac45-a87bd069c5a7",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af661bf-4f0c-4380-9981-a52a490a9276",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "Serie = monodimensionali, possono contenere qualsiasy data type. Contengono indice e valore.\\\n",
    "Dataframe = struttura 2d che contiene più serie\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c754242-1051-4084-b3f7-ed332072e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "variabile = pd.Series([1,2,[5,6], \"ciao\", np.nan])\n",
    "variabile2 = pd.Series([1,2,[5,6], \"ciao\", np.nan], index=[\"Camilla\", \"Francesco\", \"Giada\", 5,7])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b23bd5-9aa2-4006-9962-2f1be404fdd3",
   "metadata": {},
   "source": [
    "Possiamo accedere a indice e valori, usando nomeserie.index oppure nomeserie.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66295652-1c98-48f4-8574-ea4abed3a893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "[5, 6]\n",
      "ciao\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "for el in variabile2.values:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646b1528-fb27-4ed3-8ec5-edb02de64d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index Camilla for the value 1\n",
      "The index Francesco for the value 2\n",
      "The index Giada for the value [5, 6]\n",
      "The index 5 for the value ciao\n",
      "The index 7 for the value nan\n"
     ]
    }
   ],
   "source": [
    "for index in variabile2.index:\n",
    "    print(\"The index %s for the value %s\" %(index,variabile2[index]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3695eca-f44b-4e40-8b8c-ca6705a01287",
   "metadata": {},
   "source": [
    "Per creare una serie con pd.Series aggiungo sempre ( ):\\\n",
    "-se ho un insieme di chiavi:valori aggiungo anche le graffe ( { } )\\\n",
    "-se ho una lista per i valori e una lista per le chiavi, la sintassi sarà ([ ], index =[ ])\\\n",
    "pd.Series = ( [valori], index=[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c152359-3c7d-45a7-b8d7-9d2dc8f6ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.Series([28, 15, 30, 24, 10, 19], \n",
    "                     index = ['Lorenzo', 'Alessandra', 'Sofia', 'Giovanni', 'Matteo', 'Chiara'])\n",
    "print(students)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf01164-6d6d-4681-b171-157d74709f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(students[students>=18])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "002786c6-508d-4307-92fa-12b6536ad5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy         Rome\n",
      "Germany     Berlin\n",
      "France       Paris\n",
      "Spain       Madrid\n",
      "Portugal    Lisbon\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# é possibile creare una serie a partire da un dizionario\n",
    "\n",
    "capitals = pd.Series(\n",
    "    {\n",
    "        'Italy': 'Rome',\n",
    "        'Germany': 'Berlin',\n",
    "        'France': 'Paris',\n",
    "        'Spain': 'Madrid',\n",
    "        'Portugal': 'Lisbon'\n",
    "    }  \n",
    ")\n",
    "print(capitals)\n",
    "print(type(capitals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e91e623-6d6d-4ed7-9caa-28bac763b8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy       58800000\n",
      "Spain       48400000\n",
      "Germany     84400000\n",
      "Portugal    10400000\n",
      "France      68200000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "population_dict = {'Italy': 58_800_000, \n",
    "                   'Spain': 48_400_000, \n",
    "                   'Germany': 84_400_000, \n",
    "                   'Portugal': 10_400_000, \n",
    "                   'France': 68_200_000}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "print(population)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393e18e-f669-423b-9558-66accff0dfca",
   "metadata": {},
   "source": [
    "### Trasformazioni Serie\n",
    "Le serie possono essere anche (ri) convertite in dizionari e liste di Python.\\\n",
    "-Nel caso dei dizionari sarà un dizionario che rispetta la struttura della serie chiave valore\n",
    "```python\n",
    "nomeserie.to_dict()\n",
    "```\n",
    "-Nel caso delle liste sarà una lista di valori \n",
    "```python\n",
    "nomeserie.to_list()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5782f2ff-d0c7-4aac-9de1-1dcccda6082c",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc71ca9-4820-4870-9167-1374183a723e",
   "metadata": {},
   "source": [
    "Per creare un dataframe a partire da delle serie (capitals & population) il comando è\\\n",
    "pd.DataFrame( { nomecolonna1, nomecolonna2 } )\n",
    "Quando utilizzo la funzione pd.Series oppure pd.DataFrame, devo inserire:\\\n",
    "-sempre le tonde ( )\\\n",
    "-nel caso in cui non trasformo direttamente una variabile, ma parto con delle chiavi:valori, devo aggiungere anche ( { } )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14c4143b-edee-40da-bf03-a7a3b0e6725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         capitals  population\n",
      "France      Paris    68200000\n",
      "Germany    Berlin    84400000\n",
      "Italy        Rome    58800000\n",
      "Portugal   Lisbon    10400000\n",
      "Spain      Madrid    48400000\n"
     ]
    }
   ],
   "source": [
    "countries = pd.DataFrame({'capitals': capitals, 'population': population})\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecd440e8-74dd-451e-bf26-01f85183ea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France       Paris\n",
       "Germany     Berlin\n",
       "Italy         Rome\n",
       "Portugal    Lisbon\n",
       "Spain       Madrid\n",
       "Name: capitals, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Per selezionare una colonna (una serie) da un dataframe la sintassi sarà: dataframe['nomecolonna']:\n",
    "countries['capitals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "667e1d55-7552-4fa2-8bbf-728da2ac37d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Germany    Berlin\n",
       "Italy        Rome\n",
       "Name: capitals, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Per selezionare un subset di elementi di una cetta colonna\n",
    "countries['capitals'][1:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f11b3-cbe3-4064-b1ca-bffa3189e17a",
   "metadata": {},
   "source": [
    "Per accedere alle colonne di un dataframe: \n",
    "```python\n",
    "dataframe.columns\n",
    "```\n",
    "Per accedere agli indici di un dataframe:\n",
    "```python\n",
    "dataframe.index\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37642ce4-d2e1-4ad6-85fc-c6cc554f071f",
   "metadata": {},
   "source": [
    "### Trasformazioni DataFrame \n",
    "```python\n",
    "dizionario = dataframe.to_dict()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61dad5-195e-4451-9cbb-e96c012f824a",
   "metadata": {},
   "source": [
    "# Analisi di un dataframe (numero righe, colonne, elementi)\n",
    "\n",
    "- **shape**\\\n",
    "tupla (numero righe, numero colonne)\n",
    "```python\n",
    "dataframe.shape\n",
    "```\n",
    "- **size**\\\n",
    "Resituisce il numero di elementi come numero intero (righe*colonne)\n",
    "```python\n",
    "dataframe.size\n",
    "```\n",
    "- **info()**\n",
    "\n",
    "\n",
    "```python\n",
    "dataframe.info()\n",
    "```\n",
    "- **head()** \\\n",
    "Restituisce di default le prime 5 righe, altrimenti il numero viene passato come argomento\n",
    "\n",
    "- **tail()** \\\n",
    "Restituisce di default le ultime 5 righe, altrimenti il numero viene passato come argomento\n",
    "\n",
    " \n",
    "- **describe()** \\\n",
    "Genera un insieme di statistiche relative al dataframe\n",
    "```python\n",
    "dataframe.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51d599-10c3-411e-b8f0-2253ac3e97f8",
   "metadata": {},
   "source": [
    "## Accedere a colonne selezionate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a98688-8c92-43ed-aca9-07c0ed8c7745",
   "metadata": {},
   "source": [
    "Mentre **dataframe.columns** accedde a tutte le colonne, si può scegliere solo certe colonne con vari metodi: \\\n",
    "\n",
    "```python\n",
    "dataframe.colonna\n",
    "dataframe['colonna']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2bee75-c959-4ce4-9dce-26226f6381d0",
   "metadata": {},
   "source": [
    "## Creare nuove colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc70a8-6906-4fd3-9fff-766289415bd7",
   "metadata": {},
   "source": [
    "```python\n",
    "df['NUOVAcolonna'] = variabile\n",
    "df.NUOVAcolonna = variabile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be9a01-a3f9-42e6-bf3f-4cb0c2c2a10d",
   "metadata": {},
   "source": [
    "## Accedere a righe selezionate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7cdd3-128c-4490-bf9c-41dd964f2c4a",
   "metadata": {},
   "source": [
    "\n",
    "- **loc[ ]** \\\n",
    "Accede alle righe basandosi o sull'indice (ex.400) o sulle condizioni di una colonna. \\\n",
    "Per visulizzare solo la colonna in cui si pone una condizione, dopo questa condizione bisogna esplicitare il nome della colonna (ex. 'NO2'), altrimenti verrebbe visualizzato l'intero dataframe con tutte le colonne.\n",
    "```python\n",
    "df.loc['ColonnaA']\n",
    "df.loc['ColonnaA' , 'ColonnaB']\n",
    "df.loc[df.colonna > 50] \n",
    "df.loc[df.colonna > 50] = 0\n",
    "df.loc[df.colonna > 50] = np.nan\n",
    "df.loc[condizione1] & [condizione2]\n",
    "df.loc[df.NO2<0, 'NO2'])\n",
    "```\n",
    "Loc[] può essere usato anche per ottenere i valori di una riga, specficando il nome della riga come argomento --> si ottiene la serie Pandas di tutti i valori corrispondenti a quella riga. \\\n",
    "Se si aggiunge anche *.at('nomecolonnaX')* viene mostrata solo il valore di intersezione tra riga (passata come parametro di loc) e colonna (passata come parametro di at)\n",
    "\n",
    "```python\n",
    "df.loc[400]\n",
    "df.loc['rigaX']\n",
    "df.loc['rigaX'].at('colonnaY')\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- **query( )** \\\n",
    "L'argomento di query è una condizione da imporre ai dati. Il risultato è un **dataframe filtrato** \\\n",
    "Accede alle righe basandosi o sull'indice (ex.400) o sulle condizioni di una colonna.\\\n",
    "Per **2 condizoni** usare **and**\n",
    "\n",
    "```python\n",
    "dataframe.query('colonna')\n",
    "dataframe.query('colonna == \"valore\"')  \n",
    "nuovodf = dataframe.query('country == \"italy\" and indicator==\"cases\" and death= \"%d\"' %deaths)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c1d9a-c76b-4b2b-85a5-0f849d1b9861",
   "metadata": {},
   "source": [
    "# Funzioni utili \n",
    "1.  **unique()** \\\n",
    "Viene applicata a una colonna e crea una **lista**(in realtà un array, nevermind) contenente i valori unici nella colonna selezionata\n",
    "\n",
    "```python\n",
    "df.['colonna'].unique()\n",
    "df.colonna.unique()\n",
    "```\n",
    "\n",
    "2. **sum()** \\\n",
    "Restituisce la somma dei valori di una colonna\n",
    "```python\n",
    "df['colonna'].sum()\n",
    "df.colonna.sum()\n",
    "```\n",
    "\n",
    "3. **max()** & **min()** \\\n",
    "Restituisce il massimo o il minimo dei valori di una colonna\n",
    "```python\n",
    "df['colonna'].max()\n",
    "df.colonna.min()\n",
    "```\n",
    "\n",
    "4.  **nunique()** \\\n",
    "Restituisce il **numero totale** di valori diversi di ciascuna colonna o l'intero dataframe.\\\n",
    "df.nunique==len(df.unique)\n",
    "\n",
    "```python\n",
    "df.nunique()\n",
    "df['colonna'].nunique()\n",
    "df.colonna.nunique()\n",
    "```\n",
    "5. **cut()** \\\n",
    "Serve per categorizzare, cioè convertire variabili continue in variabili categoriche.\\\n",
    "Può avere 3 argomenti: \\\n",
    "-1° si riferisce a una o più colonne del dataframe\n",
    "-2° si riferisce ai bins (categorie). Può essere un numero o una lista di numeri.\n",
    "-3° si riferisce ai labels\n",
    "```python\n",
    "pd.cut(df.nomecolonna, bins=N , labels = (\"label1\", \"label2\", ..., \"labelN\"))\n",
    "```\n",
    "6. **count()** \\\n",
    "Restituisce il numero di valori non nulli. \\\n",
    "Da solo è inutile perché corrisponde al numero di righe. Invece è utile quando usato dopo la funzione groupby().\n",
    "\n",
    "```python\n",
    "pd.groupby('nomecolonna(corrisponde_alla_categoria') ['colonna_su_cui_applico_count'].count()\n",
    "```\n",
    "\n",
    "7. **sort_values()** \\\n",
    "Ordina i valori di defualt in ordine crescente.\n",
    "- *ascending*: se è false, ordine decrescente\n",
    "- *by*: non ordina contemporanemnte per due colonne, ma prima ordina per la prima colonna e solo in caso di parità per la seconda\n",
    "```python\n",
    "df.nomecolonna.sort_values()\n",
    "df.sort_values(by='nomecolonna')\n",
    "df.sort_values(by=['nomecolonna1' 'nomecolonna2'])\n",
    "df.nomecolonna.sort_values(ascending =False)\n",
    "```\n",
    "\n",
    "8. **iterrows()** \\\n",
    "Permette di iterare su *index,row* perché la funzione restituisce una tupla del tipo (indice, valore nella riga).\\\n",
    "Converte ogni riga in una serie di Pandas.\n",
    "\n",
    "\n",
    "```python\n",
    "for index,row in df.iterrows():\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    temporary_tuple =(row['colonnaA'], row['colonnaB'], row['colonnaC'])\n",
    "    \n",
    "   for index,row in df.iterrows():\n",
    "       temporary_tuple =(row[0], row[1], row[2])\n",
    "```\n",
    "\n",
    "9. **set_index()** \\\n",
    "Trasforma una colonna nell'indice del dataframe\n",
    "```python\n",
    "df.set_index('nomecolonna', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "11. **plot()**\n",
    "-title = testo\n",
    "-kind = scatter / bar(istogramma)\n",
    "-x = valore da mettere sulle x. Se non indicato, di default è l'indice (nei grouped_dataframe, sarà la categoria)\n",
    "-y = valore da mettere sulle y\n",
    "-xlabel = testo\n",
    "-ylabel = testo\n",
    "c = colore che si vuole usare\n",
    "\n",
    "```python\n",
    "\n",
    "colors= {\"setosa\": \"purple\", \"versicolor\":\"green\", \"virginica\":\"blue\"}\n",
    "\n",
    "iris_df.plot(title='petal_length vs. petal_width', \n",
    "             kind='scatter',\n",
    "             x='petal_length', y='petal_width', \n",
    "             xlabel='Petal length', ylabel='Petal width',\n",
    "             c=iris_df['species'].map(colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d063f02-dc6c-471e-a246-cb63586f6f23",
   "metadata": {},
   "source": [
    "# Pulizia dati (data cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd39a3f-dfeb-457d-bb59-456e6126e284",
   "metadata": {},
   "source": [
    "Quando si esegue il data cleaning bisogna capire qual è lo scopo per cui si opera il filtraggio:\\\n",
    "- Se si vuole plottare il dataframe (nel tempo) --> Settare a 0 valori incongrui (-999, outliers)\n",
    "- Se si vuole fare un'analisi statistica --> Settare a NaN (perché lo 0 andrebbe a influenzare i calcoli, come per la media)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef247c-ca36-4c46-9cbf-49be66ddeb03",
   "metadata": {},
   "source": [
    "1.  **dropna()** \\\n",
    "Funzione che permette di eliminare tutti gli elementi con valore NaN.(Distinzione: se si vuole assegnare il valore NaN, la sintassi è *np.nan*, poi ciò che compare è solo *NaN*. \n",
    "dropna() elimina tutte le righe del dataframe che contengono un valore NaN almeno in una colonna\n",
    "\n",
    "```python\n",
    "dataframe.dropna()\n",
    "dataframe.dropna(inplace=True, subset=['colonna'])\n",
    "```\n",
    "\n",
    "2. **dropduplicates()** \\\n",
    "Funzione che permette di rimuovere i valori duplicati nel dataframe.\\\n",
    "Sia per *dropduplicates()* che per *dropna()* è possibile svolgere l'operazione solo su alcune colonne selezionate.\n",
    "*Inplace=True* evita che l'utilizzo delle funzioni generi un nuovo dataframe, mentre *subset* seleziona le colonne.\n",
    "```python\n",
    "dataframe.dropduplicates()\n",
    "dataframe.dropduplicates(inplace=True, subset=['colonna'])\n",
    "```\n",
    "3. **fillna()** \\\n",
    "Funzione simila a *dropna()*, ma sostituisce i valori NaN con un valore di nostro piacimento.\\\n",
    "**Importante**: *fillna()* non prende il parametro subset, quindi per esplicitare la colonna su cui applicare la funzione bisogna usare la sintassi per accedere alle colonne prima di scrivere fillna().\n",
    " \n",
    "```python\n",
    "df.colonna.fillna(0, inplace=True)\n",
    "df.colonna.fillna(df.colonna.mean(), inplace=True)\n",
    "df.colonna.fillna(df.colonna.max(), inplace=True)\n",
    "df.colonna.fillna(df.colonna.std(), inplace=True)\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c798b8-db0c-46a9-b4c3-584a650872a0",
   "metadata": {},
   "source": [
    "# Standardizzazione (Data Standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1cb4b-b1b7-4d76-8824-386cc2b8aabf",
   "metadata": {},
   "source": [
    "Trasforma i dati delle colonne in modo che seguano un andamento gaussiano con  **media=0** e **deviazione standard=1** \\\n",
    "Bisogna importare una classe da un modulo. \\\n",
    "1. Creare una variabile *scaler* che sia un oggetto della classe *StandardScaler*\n",
    "2. Convertire i valori standardizzati in una variabile *df_scaled* (NON è un dataframe)\n",
    "3. Convertire la variabile standardizzata *df_scaled* in un dataframe *df_scaled*\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_unscaled)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns= df_unscaled.columns)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b4b28-5461-4a94-9e5f-a4cfe145c67a",
   "metadata": {},
   "source": [
    "# Normalizzazione (Data Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d8ed8-c6db-48e3-942c-2f5e6e236b77",
   "metadata": {},
   "source": [
    "Trasforma i dati delle colonne in modo che siano in un **range da 0 a 1** \n",
    "1. Creare una variabile *scaler* che sia un oggetto della classe *MinMaxScaler*\n",
    "2. Convertire i valori standardizzati in una variabile *df_scaled* (NON è un dataframe)\n",
    "3. Convertire la variabile standardizzata *df_scaled* in un dataframe *df_scaled*\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_unscaled)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns= df_unscaled.columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda47579-704f-4894-9b2f-0d7460938836",
   "metadata": {},
   "source": [
    "# CSV and XLSX -->  DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35244e2-5e23-48fc-b137-622b7be85564",
   "metadata": {},
   "source": [
    "La funzione *pd.read_csv()* **crea automaticamente un dataframe**. \\\n",
    "Si possono leggere solo alcune colonne di un csv tramite il parametro *usecols* che può essere una variabile precedentemente creata come lista di nomi di colonne, colonne di un altro dataframe, ecc..\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('nomefile.csv')\n",
    "df = pd.read_csv('nomefile.csv', usecols= subset)\n",
    "```\n",
    "```python\n",
    "! pip install openpyxl\n",
    "df = pd.read_excel('nomefile.xlsx')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0c654-3e7f-4490-9d42-213ad23c68bf",
   "metadata": {},
   "source": [
    "# ESPORTARE DF--> XLSX\n",
    "```python\n",
    "nome_dataframe_da_esportare.to_excel('nome_file.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c357c4-0a83-4e55-98a0-b83739b98d30",
   "metadata": {},
   "source": [
    "# TIME\n",
    "\n",
    "## 1) DATETIME OBJECT\n",
    "Nel caso avessimo un dataframe con 4 colonne corrispondenti a  year, month, day, hour possiamo creare un oggetto datetime (tipico di pandas) che racchiude tutte queste informazioni in un solo oggetto.\\\n",
    "In questo modo compattiamo 4 colonne in una nuova colonna che chiameremo *timerep*\n",
    "\n",
    "```python\n",
    "df['timerep'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "```\n",
    "\n",
    "La funzione *resample()* è usata quando lavoriamo con un oggetto datetime e serve a  aggrega i valori in base anni/masi. \n",
    "In questo caso stiamo unendo 24 righe (24 ore) in 1  riga sola (giorno) e il valore di questa riga sarà la media dei valori delle ore. \n",
    "```python\n",
    "df.resample('D').mean()[['PM10','PM25','NO2']]\n",
    "```\n",
    "\n",
    "## 2) TIME MODULE\n",
    "Calcolare tempo impiegato per eseguire un comando\n",
    "```python\n",
    "import time \n",
    "start_time = time.time() #Parte dal 1 gennaio del 1979\n",
    "...\n",
    "...\n",
    "end_time = time.time()\n",
    "print('Time occured' % (end_time-start_time))\n",
    "```\n",
    "\n",
    "## 3) %%timeit\n",
    "**DEVE ESSERE IL PRIMO COMANDO DELLA CELLA**\n",
    "```python\n",
    "%%timeit\n",
    "...\n",
    "```\n",
    "## 4) ISOCALENDAR()  --> datetime\n",
    "Bisogna **importare il modulo datetime** --> oggetto datetime composta da anno-mese-giorno \\\n",
    "La funzione *isocalendar()* restituisce una tupla composta da: (year, week number, weekday).\n",
    "\n",
    "``` python\n",
    "import datetime\n",
    "today = datetime.date.today()\n",
    "```\n",
    "\n",
    "``` python\n",
    "import datetime\n",
    "def week_string(year, month, day):\n",
    "    ''' return a week number in the format yyyy-ww; for example,\n",
    "    2021-45 for the 45th week of the year 2021. '''\n",
    "    week = datetime.date(year, month, day).isocalendar()[1]\n",
    "    return \"%s-%02d\" % (year, week)\n",
    "\n",
    "# example: find the week string for March 1, 2020\n",
    "print(week_string(2020, 3, 1))\n",
    "\n",
    "# example: find the week string for November 30, 2021\n",
    "print(week_string(2021, 11, 30))\n",
    "```\n",
    "- % - This tells the interpreter that a variable should be inserted here.\n",
    "\n",
    "- 02 - This tells the interpreter to expect the variable to be 2 in length.\n",
    "\n",
    "- d - This tells the interpreter to expect a number, or should we say a\"'d’igit\".\n",
    "\n",
    "- Therefore what %02d represents is a digit of length 2 --> In this way 9--> 09\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
